{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4f6572",
   "metadata": {},
   "source": [
    "# Supervised Learning - Classification Problem\n",
    "\n",
    "## Students' dropout and academic success\n",
    "\n",
    "### (Droupout, Enrolled, Graduate)\n",
    "\n",
    "Faculdade: FEUP - Faculdade de Engenharia da Universidade do Porto\n",
    "\n",
    "Curso: L.EIC - Licenciatura em Engenharia Informática e Computação \n",
    "\n",
    "Unidade Curricular: Inteligência Artificial\n",
    "\n",
    "Ano Curricular: 2021/22\n",
    "\n",
    "Grupo: 21_1D\n",
    "\n",
    "Elementos:\n",
    "- Henrique Ribeiro Nunes, up201906852@up.pt\n",
    "- Margarida Assis Ferreira, up201905046@up.pt\n",
    "- Patrícia do Carmo Nunes Oliveira, up201905427@up.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a62f5",
   "metadata": {},
   "source": [
    "### Specification\n",
    "\n",
    "O foco principal deste problema é analisar a informação conhecida sobre a matrícula do aluno (percurso acadêmico, demografia e fatores socioeconómicos) e o desempenho académico dos alunos no final do primeiro e segundo semestres. Com o objetivo de usar estes dados para construir modelos de classificação para **prever a desistência e o sucesso académico dos alunos**.\n",
    "\n",
    "Este problema é um ***single label multiclass classification problem*** com 37 atributos:\n",
    "- 36 métricas distintas para descrever as informações do aluno.\n",
    "- 1 objetivo com 3 resultados possíveis (*Droupout*, *Enrolled*, *Graduate*).\n",
    "\n",
    "Existe um **forte desbalanceamento** em relação a um dos resultados possíveis.\n",
    "\n",
    "\n",
    "### Tools & Resources\n",
    "\n",
    "* [Como balancear um dataset](https://towardsdatascience.com/how-to-balance-a-dataset-in-python-36dff9d12704)\n",
    "* [Como lidar com desbalanceamento em ML](https://www.analyticsvidhya.com/blog/2020/07/10-techniques-to-deal-with-class-imbalance-in-machine-learning/)\n",
    "* [Método pandas.DataFrame.duplicated()](https://www.machinelearningplus.com/pandas/pandas-duplicated/)\n",
    "* [Vizualização de distribuições de dados](https://seaborn.pydata.org/tutorial/distributions.html)\n",
    "* [Guia de Scikit Learn](https://scikit-learn.org/stable/user_guide.html)\n",
    "* [Plot de gráficos com múltiplas barras](https://www.geeksforgeeks.org/plotting-multiple-bar-charts-using-matplotlib-in-python/)\n",
    "* [Grid Search para Decision Trees](https://ai.plainenglish.io/hyperparameter-tuning-of-decision-tree-classifier-using-gridsearchcv-2a6ebcaffeda)\n",
    "* [Refinamento de hiperparâmetros com Grid Search](https://medium.datadriveninvestor.com/hyperparameter-tuning-with-deep-learning-grid-search-8630aa45b2da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053a6b0",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "A análise dos dados é um passo importante nos problemas de classificação. \n",
    "\n",
    "Nesta secção são analisados os atributos que classificam os dados e o tipo e intervalo de valores de cada um dos atributos, bem como o tamanho do conjunto de dados, a presença de valores nulos ou amostras duplicadas. Igualmente é explorado a distribuição das classes e de valores por atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865da361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca83edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FILE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"data/data_original.csv\")\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc6cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print head values and summary statistics\n",
    "print(data.describe())\n",
    "print()\n",
    "print(data.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3cba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all 36 features used and 3 possible results\n",
    "features = list(data.columns)\n",
    "features.remove(\"class\")\n",
    "print(\"Number of Features: {}\".format(len(features)))\n",
    "print(\"Features: {}\".format(features))\n",
    "values = list(data[features].values)\n",
    "\n",
    "classes = list(data[\"class\"].unique())\n",
    "classes.sort()\n",
    "print(\"\\nNumber of Results: {}\".format(len(classes)))\n",
    "print(\"Result/Prediction: {}\".format(classes))\n",
    "targets = list(data[\"class\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a89968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check atribute types and values interval\n",
    "for name, dtype in data.dtypes.iteritems():\n",
    "    print(\"{} | {} | [{} , {}] \".format(name.ljust(46), str(dtype).ljust(7), data[name].min(), data[name].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data size\n",
    "print(\"Data Size: {}\".format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2557c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are columns with N/A values\n",
    "print(\"N/A values found: {}\".format(data.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af6dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are duplicated Data\n",
    "bool_series = data.duplicated()\n",
    "print(bool_series)\n",
    "\n",
    "old_size = len(data)\n",
    "\n",
    "# Removing all duplicated data if exists\n",
    "data = data[~bool_series] \n",
    "\n",
    "new_size = len(data)\n",
    "\n",
    "# check if there were actualy duplicated data\n",
    "print()\n",
    "if (new_size == old_size):\n",
    "    print(\"No data was removed: there were no duplicated data\")\n",
    "else:\n",
    "    print(\"Was found and removed {} duplicated data\".format(old_size-new_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d295e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultant data without duplicated entries\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count each class\n",
    "def countEachClass(data):\n",
    "    n_dropouts = data['class'].value_counts().Dropout\n",
    "    n_enrolled = data['class'].value_counts().Enrolled\n",
    "    n_graduate = data['class'].value_counts().Graduate\n",
    "    return n_dropouts, n_enrolled, n_graduate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61232f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data rows associated with each class\n",
    "def sampleEachClass(data):\n",
    "    class_dropout = data[data['class'] == \"Dropout\"]\n",
    "    class_enrolled = data[data['class'] == \"Enrolled\"]\n",
    "    class_graduate = data[data['class'] == \"Graduate\"]\n",
    "    return class_dropout, class_enrolled, class_graduate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e789768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Distribution\n",
    "# Check data balance\n",
    "n_dropouts, n_enrolled,n_graduate = countEachClass(data)\n",
    "print(\"Number of 'Dropout' occurences: {}\".format(n_dropouts))\n",
    "print(\"Number of 'Enrolled' occurences: {}\".format(n_enrolled))\n",
    "print(\"Number of 'Graduate' occurences: {}\".format(n_graduate))\n",
    "print()\n",
    "\n",
    "# Corresponding plot \n",
    "count_result = pd.DataFrame(data[\"class\"]).value_counts().rename_axis(\"class\").reset_index(name=\"count\")\n",
    "print(count_result)\n",
    "\n",
    "# Bar plot\n",
    "plot_count_res = sb.barplot(data=count_result, x=\"count\", y=\"class\")\n",
    "plt.show()\n",
    "\n",
    "# Pie plot with percentages\n",
    "plt.pie([n_graduate, n_dropouts, n_enrolled], autopct = '%0.00f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd29a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for each feture values and respective count of classses\n",
    "\n",
    "def count_targets_for_each_value(data, feat):\n",
    "    data_aux = data[[feat, \"class\"]]\n",
    "    d = {}\n",
    "    for line in data_aux.values:\n",
    "        if not line[0] in d:\n",
    "            d[line[0]] = {classes[0]: 0, classes[1]: 0, classes[2]: 0}\n",
    "        d[line[0]][line[1]] += 1\n",
    "\n",
    "    for entry in d.keys():\n",
    "        d[entry] = [d[entry][c] for c in classes]\n",
    "    aux = pd.DataFrame(d, index=classes)\n",
    "    return aux.reindex(sorted(aux.columns), axis=1)\n",
    "\n",
    "\n",
    "for i in range(36):\n",
    "    plt.title(features[i])\n",
    "    plt.hist(data[features[i]].values)\n",
    "    plt.show()\n",
    "    print(count_targets_for_each_value(data, features[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e5f0fc",
   "metadata": {},
   "source": [
    "Analisando a distribuição de cada atributo pelas classes possíveis, podemos concluir que existem alguns atributos irrelevantes, na medida que não se distingue à priori nem se obtem qualquer informação sobre qual a classe mais provável para uma nova amostra com base no valor desse atributo, como conseguimos identifificar no caso do atributo 'Curricular units 2nd sem (credited)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c21a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of each attribute \n",
    "def densityPlot(x, hue, fill):\n",
    "    sb.displot(data, x=x, hue=hue, kind=\"kde\", fill=fill)\n",
    "    \n",
    "# all 36 distinct attributes\n",
    "attributes = list(data.columns)\n",
    "attributes.remove(\"class\")\n",
    "    \n",
    "for attribute in attributes:\n",
    "    densityPlot(attribute, 'class', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d2a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "\n",
    "corr = data.corr()\n",
    "\n",
    "sb.set(rc = {'figure.figsize': (15,15) })\n",
    "ax = sb.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sb.diverging_palette(20, 240, n=200),\n",
    "    square=True,\n",
    "    xticklabels=True,\n",
    "    yticklabels=True,\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "plt.show()\n",
    "\n",
    "sb.reset_orig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa5929",
   "metadata": {},
   "source": [
    "**Propriedades do Problema:** (a partir da análise dos dados de entrada)\n",
    "\n",
    "- Nominal and Discrete attributes (including some binary ones)\n",
    "- Dimensionality = 37 attibutos\n",
    "- Size = 4424\n",
    "- Type = Data Matrix\n",
    "- No missing or duplicate Data\n",
    "- No meaningful outliers\n",
    "- Imbalance data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ea0a2",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Tendo em conta as conclusões obtidas pela a análise dos dados originais mostrada anteriormente, podemos apercebermo-nos que é necessário realizar um pré-processamento dos dados, com o objetivo de resolver o maior problema adjacente a estes: a falta de balanceamento entre as diferentes classes de alvo. \n",
    "\n",
    "Para tal podemos usar entre outras estratégias uma das seguintes:\n",
    "- **oversampling** : «Aumentar o número de amostras/entradas da menor classe até coincidir com o tamanho da maior classe»\n",
    "- **undersampling** : «Diminuir o número de amostras/entradas da maior classe até coincidir com o tamanho da menor classe»\n",
    "\n",
    "Em qualquer uma das abordagens acima, a escolha das amostras escolhidas para serem retidas ou replicadas com pequenas modificações é aleatória.\n",
    "\n",
    "Foi também necessário proceder à padronização dos dados para tornar a existência de _oultiers_ menos relevante e equiparar a escala de cada atributo para assim melhorar a performance de alguns algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38bc900",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b3b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize(data, to_standardize):\n",
    "    data_to_standardize = data[to_standardize]\n",
    "    scaler = StandardScaler()\n",
    "    stand_values = scaler.fit_transform(data_to_standardize.values)\n",
    "\n",
    "    stand_values_df = pd.DataFrame(\n",
    "        stand_values, \n",
    "        index=data_to_standardize.index, \n",
    "        columns=to_standardize)\n",
    "    data[to_standardize] = stand_values_df[to_standardize]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbac5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_binary_features = [feature for feature in features if len(data[feature].unique()) != 2]\n",
    "data_standard = standardize(data.copy(), non_binary_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa0503",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "\n",
    "Uma das técnicas para lidar com o desbalanceamento de classes em machine lerning é chamado de *undersampling*. Esta técnica de balanceamento consiste em remover algumas observações das classes majoritárias, até que as classes majoritárias e minoritárias sejam equilibradas. A técnica *undersampling* pode ser uma boa escolha quando temos dados desequilibrados, mas uma desvantagem é que removemos informações que podem ser valiosas.\n",
    "\n",
    "Para remover as observações das classes majoritárias, usamos a função `sample(sequence, k)`, uma função do módulo `Random` de Python, que retorna uma lista de comprimento `k` de itens escolhidos aleatoriamente de `sequence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalance Original Data\n",
    "print(\"Classes count:\")\n",
    "print(data['class'].value_counts())\n",
    "\n",
    "data['class'].value_counts().plot(kind='bar', title='count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1232ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersampling(data):\n",
    "    n_dropouts,n_enrolled,n_graduate = countEachClass(data)\n",
    "    class_dropout,class_enrolled,class_graduate = sampleEachClass(data)\n",
    "    \n",
    "    class_dropout_under = class_dropout.sample(n_enrolled, replace=True)\n",
    "    class_graduate_under = class_graduate.sample(n_enrolled, replace=True)\n",
    "    return pd.concat([class_dropout_under, class_graduate_under, class_enrolled], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc02d2c",
   "metadata": {},
   "source": [
    "Agora temos os nossos dados balanceados, como é possível observer no gráfico criado pelo código abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9684b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_under = undersampling(data)\n",
    "\n",
    "# plot the count after under-sampeling\n",
    "print(\"Classes count after under-sampling:\")\n",
    "print(data_under['class'].value_counts())\n",
    "\n",
    "data_under['class'].value_counts().plot(kind='bar', title='count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb5d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "if SAVE_FILE: data_under.to_csv(\"data/data_under.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f401a522",
   "metadata": {},
   "source": [
    "### Oversampling\n",
    "\n",
    "As entradas da classe menor sáo replicadas até totalizarem o número de amostras da classe maior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dropouts,n_enrolled,n_graduate = countEachClass(data)\n",
    "\n",
    "print(\"DROPOUT: {} | ENROLLED: {} | GRADUATE: {}\".format(n_dropouts, n_enrolled, n_graduate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c76c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalance Original Data\n",
    "unbalanced_count = data['class'].value_counts()\n",
    "unbalanced_count.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd378cc",
   "metadata": {},
   "source": [
    "#### Random Over-Sampling\n",
    "\n",
    "«Oversampling can be defined as adding more copies to the minority class.»\n",
    "\n",
    "**Desvantagens:** pode causar *overfitting* e pobre generalização do conjunto de dados para teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabeda45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(data):\n",
    "    n_dropouts,n_enrolled,n_graduate = countEachClass(data)\n",
    "    dropout_samples,enrolled_samples,graduate_samples = sampleEachClass(data)\n",
    "\n",
    "    dropout_samples_over = dropout_samples.sample(n_graduate, replace=True)\n",
    "    enrolled_samples_over = enrolled_samples.sample(n_graduate, replace=True)\n",
    "\n",
    "    return pd.concat([graduate_samples, dropout_samples_over, enrolled_samples_over], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7267a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_over = oversampling(data)\n",
    "print(\"Total dintinct classes: \\n{}\".format(data_over['class'].value_counts()))\n",
    "\n",
    "rnd_oversampling_count = data_over['class'].value_counts()\n",
    "rnd_oversampling_count.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19bff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "if SAVE_FILE: data_over.to_csv(\"data/data_over.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38a7814",
   "metadata": {},
   "source": [
    "É importante referir que nenhuma das soluções acima é uma solução perfeita, pois a aplicação de undersampling pode implicar a perda de infromação, da mesma forma que a aplicação de oversampling (sem qualquer modificação das amostras escolhidas aleatóriamente para serem replicadas) pode levar a um posterior overfitting dos modelos gerados a estes novos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9caea49",
   "metadata": {},
   "source": [
    "### Combine under and over sampling\n",
    "\n",
    "Tendo isto em conta a seguinte tentativa tenta encontrar um meio termos entre as soluções anteriores, fazendo as classes em questão convergir para um valor mediano e não para um máximo nem minímo, tentando combater as consequencias sentidas nos dados ao aplicar isoladamente cada uma das estratégias, obtando por alcaçar um meio termo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c6f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the counts meet at the middle point\n",
    "# in this case the middle point is consider to be the dropout class\n",
    "def combine_sampling(data):\n",
    "    n_dropouts,n_enrolled,n_graduate = countEachClass(data)\n",
    "    dropout_samples,enrolled_samples,graduate_samples = sampleEachClass(data)\n",
    "    graduate_samples_combine = graduate_samples.sample(n_dropouts, replace=True)\n",
    "    enrolled_samples_combine = enrolled_samples.sample(n_dropouts, replace=True)\n",
    "    return pd.concat([graduate_samples_combine, dropout_samples, enrolled_samples_combine], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combine = combine_sampling(data)\n",
    "\n",
    "print(\"Total dintinct classes: \\n{}\".format(data_combine['class'].value_counts()))\n",
    "\n",
    "combine_count = data_combine['class'].value_counts()\n",
    "combine_count.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d367ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "if SAVE_FILE: data_combine.to_csv(\"data/data_combine.csv\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c9dcd",
   "metadata": {},
   "source": [
    "## Learning Algorithms\n",
    "\n",
    "### Identification of the Target Concept\n",
    "\n",
    "A pergunta a que queremos responder é a seguinte: \"Tendo em conta o percurso académico de um aluno e outros fatores externos como é que conseguimos prever se este vai desistir, graduar ou continuar no mesmo ano?\"\n",
    "\n",
    "De forma a avaliar os modelos posterioemente criados podemos escolher nesta secção se os dados a usar ai foram proviamente standarizados e qual o tipo de estratégia para corrigir o balanceamento que é utilizada (inclusive nenhuma). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9407e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameteres of the pre-processing and construction of the model for the data\n",
    "STANDARDIZATION = True\n",
    "BALANCETECNIQUE = 'OVER'\n",
    "\n",
    "# original data\n",
    "data = pd.read_csv('data/data_original.csv')\n",
    "\n",
    "if STANDARDIZATION:\n",
    "    non_binary_features = [feature for feature in features if len(data[feature].unique()) != 2]\n",
    "    data = standardize(data, non_binary_features)\n",
    "\n",
    "if BALANCETECNIQUE == 'UNDER': data = undersampling(data)\n",
    "elif BALANCETECNIQUE == 'OVER': data = oversampling(data)\n",
    "elif BALANCETECNIQUE == 'COMBINE': data = combine_sampling(data)\n",
    "\n",
    "values = list(data[list(data.columns[:-1])].values)\n",
    "targets = list(data['class'].values)\n",
    "\n",
    "GRIDSEARCH = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc0c38",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3926cc",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac83c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_data(data, classes, test_size):\n",
    "  feat_train, feat_test, target_train, target_test = train_test_split(data, classes, test_size=test_size, shuffle=True)\n",
    "  return feat_train, feat_test, target_train, target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c0e02",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def cross_validation(model, features, targets, cv):\n",
    "    scores = cross_val_score(model, features, targets, cv=cv)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2d0ac",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed661554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "def confusion_matrix(target_test, target_predictions):    \n",
    "    return metrics.confusion_matrix(target_test, target_predictions)\n",
    "\n",
    "def display_confusion_matrix(cm):\n",
    "    metrics.ConfusionMatrixDisplay(cm, display_labels=classes).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677c27f",
   "metadata": {},
   "source": [
    "#### Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c552f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def recall(cm, i):\n",
    "    return cm[i][i]/sum(cm[i])\n",
    "\n",
    "def precision(cm, i):\n",
    "    cmt = np.copy(cm).transpose()\n",
    "    return cmt[i][i]/sum(cmt[i])\n",
    "\n",
    "def f_measure(cm, i):\n",
    "    p = precision(cm, i)*100\n",
    "    r = recall(cm, i)*100\n",
    "    return 2 * (p * r) / (p + r)\n",
    "\n",
    "def validate(model, features, targets):\n",
    "    test_size = 0.2\n",
    "    cross_validation_split = 5\n",
    "    feat_train, feat_test, target_train, target_test = split_data(features, targets, test_size)\n",
    "    \n",
    "    model.fit(feat_train, target_train)\n",
    "    predictions = model.predict(feat_test)\n",
    "    \n",
    "    acc = metrics.accuracy_score(target_test, predictions)\n",
    "    print(\"Accuracy: {:.2f}\\n\".format(acc*100))\n",
    "    \n",
    "    cm = confusion_matrix(target_test, predictions)\n",
    "    print(\"Precision:\")\n",
    "    for i in range(3): print(\"\\t{:.2f}% - {}\".format(precision(cm, i)*100, classes[i]))\n",
    "    print(\"Recall:\")\n",
    "    for i in range(3): print(\"\\t{:.2f}% - {}\".format(recall(cm, i)*100, classes[i]))\n",
    "    print(\"F1-measure:\")\n",
    "    for i in range(3): print(\"\\t{:.2f}% - {}\".format(f_measure(cm, i), classes[i]))\n",
    "        \n",
    "    scores = cross_validation(model, features, targets, cross_validation_split)\n",
    "    print(\"Cross validation {}-fold: {}\".format(cross_validation_split, [round(x, 3) for x in scores]))\n",
    "    print(\"\\t{:.2f} - accuracy\".format(scores.mean()))\n",
    "    print(\"\\t{:.2f} - standard deviation\".format(scores.std()))\n",
    "    \n",
    "    test_report = metrics.classification_report(target_test, predictions)\n",
    "    print(\"\\nTest Classification Report:\\n\", test_report)\n",
    "    \n",
    "    predictions_train = model.predict(feat_train)\n",
    "    train_report = metrics.classification_report(target_train, predictions_train)\n",
    "    print(\"\\nTrain Classification Report:\\n\", train_report)\n",
    "\n",
    "    display_confusion_matrix(cm)\n",
    "    \n",
    "    return test_report, train_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181302cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_search(model, grid_params, features, targets):\n",
    "    test_size = 0.2\n",
    "    cross_validation_split = 5\n",
    "    feat_train, feat_test, target_train, target_test = split_data(features, targets, test_size)\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        model,\n",
    "        grid_params,\n",
    "        verbose = 1,\n",
    "        n_jobs = 1,\n",
    "        cv = cross_validation_split,\n",
    "    )\n",
    "    \n",
    "    gs_results = gs.fit(feat_train, target_train)\n",
    "    \n",
    "    print(\"best score: \" + str(gs_results.best_score_))\n",
    "    print(\"best estimator: \" + str(gs_results.best_estimator_))\n",
    "    print(\"best parameters: \" + str(gs_results.best_params_))\n",
    "    \n",
    "    return gs_results.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a876e5",
   "metadata": {},
   "source": [
    "### Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05548a8",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc2329",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_TREE=False\n",
    "DOWNLOAD_TREE=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47b7fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_dtc = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'], \n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [5, 7, 10, 20],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_leaf_nodes': [None, 5, 10, 20],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(\n",
    "  criterion= 'entropy', \n",
    "  splitter= 'best', \n",
    "  max_depth= 7, \n",
    "  max_features = None, \n",
    "  max_leaf_nodes= None) \n",
    "\n",
    "if GRIDSEARCH: dtc = grid_search(DecisionTreeClassifier(), grid_params_dtc, values, targets)\n",
    "\n",
    "test_report_dtc, train_report_dtc = validate(dtc, values, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tree\n",
    "if PLOT_TREE: \n",
    "    from sklearn.tree import plot_tree\n",
    "    plot_tree(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73281f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PDF with the tree\n",
    "if DOWNLOAD_TREE:\n",
    "    import graphviz\n",
    "    from sklearn.tree import export_graphviz\n",
    "\n",
    "    dot_data = export_graphviz(dtc, out_file=None, feature_names=features, class_names=targets ) \n",
    "    graph = graphviz.Source(dot_data) \n",
    "    graph.render(\"decision_tree\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bbf312",
   "metadata": {},
   "source": [
    "#### K-nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523600ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_knn = {\n",
    "    'n_neighbors': [3,5,11,19], \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84996ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors = 9,\n",
    "    weights = 'distance',\n",
    "    metric = 'manhattan')\n",
    "\n",
    "if GRIDSEARCH: knn = grid_search(KNeighborsClassifier(), grid_params_knn, values, targets)\n",
    "\n",
    "test_report_knn, train_report_knn = validate(knn, values, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44df5cb",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92523a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_nnc = {\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'], \n",
    "    'alpha': [1e-5, 1e-2],\n",
    "    'hidden_layer_sizes': [(5, 2), (40,50)],\n",
    "    'max_iter':[5000, 200],\n",
    "    'random_state':[None, 1, 36]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b5d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nnc = MLPClassifier(\n",
    "    solver = 'sgd', \n",
    "    alpha = 1e-5,\n",
    "    hidden_layer_sizes = (40, 50),\n",
    "    max_iter = 5000,\n",
    "    random_state = 1,\n",
    "    activation = 'relu',\n",
    "    learning_rate = 'constant',\n",
    "    learning_rate_init = 0.01)\n",
    "\n",
    "if GRIDSEARCH and False: nnc = grid_search(MLPClassifier(), grid_params_nnc, values, targets)\n",
    "\n",
    "test_report_nnc, train_report_nnc = validate(nnc, values, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa01104",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d3b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_svm = {\n",
    "    'C': [0.1, 1, 10, 100], \n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'decision_function_shape': ['ovr', 'ovo']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c63c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(\n",
    "    decision_function_shape='ovr',\n",
    "    C = 10,\n",
    "    gamma=0.01,\n",
    "    kernel='rbf')\n",
    "\n",
    "if GRIDSEARCH: svm = grid_search(SVC(), grid_params_svm, values, targets)\n",
    "\n",
    "test_report_svm, train_report_svm = validate(svm, values, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c79c747",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81736967",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_rfc = {\n",
    "    'max_depth': [None, 10, 50],\n",
    "    'max_features': ['sqrt', 'log2', 15, 25],\n",
    "    'min_samples_leaf': [1, 3, 4],\n",
    "    'min_samples_split': [2, 10],\n",
    "    'n_estimators': [20, 40]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d53866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(\n",
    "    n_estimators=40,\n",
    "    max_depth=None,\n",
    "    max_features=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2)\n",
    "\n",
    "if GRIDSEARCH: rfc = grid_search(RandomForestClassifier(), grid_params_rfc, values, targets)\n",
    "\n",
    "test_report_rfc, train_report_rfc = validate(rfc, values, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb4821d",
   "metadata": {},
   "source": [
    "#### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c068bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params_etc = {\n",
    "    'max_depth': [None, 10, 50, 100],\n",
    "    'random_state': [None, 5],\n",
    "    'min_samples_split': [2, 10],\n",
    "    'n_estimators': [20, 40, 60]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a50335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier(\n",
    "    n_estimators=40, \n",
    "    max_depth=100,\n",
    "    min_samples_split=2, \n",
    "    random_state=None)\n",
    "\n",
    "if GRIDSEARCH: etc = grid_search(ExtraTreesClassifier(), grid_params_etc, values, targets)\n",
    "    \n",
    "test_report_etc, train_report_etc = validate(etc, values, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c028818",
   "metadata": {},
   "source": [
    "### Evaluation of the learning process\n",
    "\n",
    "No que diz respeito à avaliação do processo de aprendizagem foi implementada a função `validate` (apresentada na secção de *Validation*) que é responsável por dividir os dados em dados de treino e de teste, bem como avaliar os resultados obtidos em cada um dos modelos criados usando as métricas apropriadas: ***accuracy***, ***precision***, ***recall***, ***F-measure*** e ***confusion matrix***, tendo sempre em consideração as características do problema: o problema trata-se um um problema de classificação ***multiclass single label*** com 3 diferentes classes objetivo (3 *targets*). Esta avaliação centra-se principalmente no conjunto de dados de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f4c3dc",
   "metadata": {},
   "source": [
    "### Results Comparision\n",
    "\n",
    "O resultados apresentados foram obtidos apartir da comparação da avaliação de performance dos diferentes modelos considerando as seguintes combinações nas variações da data de entrada:\n",
    "\n",
    "- aplicação de **standarização** aos dados: *yes/no*\n",
    "- estratégia para **tratamento do desbalanceamento** dos dados: *none/under/over/combined*\n",
    "\n",
    "NOTA: Estes parametros podem ser ajustados e configurados no início da secção ***Learning Algorithms, «Identification of the Target Concept»***. Os parametros de cada um dos algoritmos resultaram de uma pesquisa ***Grid Search*** efetuada previamente, que por razões de tempo e performance por defeito é desabilitada.\n",
    "\n",
    "Neste sentido foram comparados os resultados obtidos para cada uma das combinações possíveis para os 3 algoritmos apresentados anteriormente : ***Decision Tree Classifier***, ***K-Nearest Neighbor***, ***Neural Networks***, ***Support Vector Machine***, ***Random Forest***, ***Extra Trees***, resultando nos seguintes gráficos, baseados nas tabelas retornadas pela função de `validate` apresentados em seguida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434bcbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"-- CONTEXT:: STANDARDIZATION: {} | BALANCETECNIQUE: {} | GRIDSEARCH: {} -- \".format(STANDARDIZATION, BALANCETECNIQUE, GRIDSEARCH))\n",
    "print()\n",
    "\n",
    "def get_x_groups(report):\n",
    "    X_GROUPS = []\n",
    "    \n",
    "    lines = list(filter(lambda line: len(line) > 1, report.split('\\n')))\n",
    "    for line in lines[1:]:\n",
    "        cells = list(filter(lambda cell: cell != '', line.split(' ')))\n",
    "        if len(cells) <= 5: X_GROUPS.append(cells[0])\n",
    "        else: X_GROUPS.append(cells[0] + ' ' + cells[1])\n",
    "    return X_GROUPS\n",
    "\n",
    "def get_fm_values(report):\n",
    "    f_values = []\n",
    "\n",
    "    lines = list(filter(lambda line: len(line) > 1, report.split('\\n')))\n",
    "    for line in lines[1:]:\n",
    "        cells = list(filter(lambda cell: cell != '', line.split(' ')))\n",
    "        f_values.append(int(float(cells[-2])*100))\n",
    "    return f_values\n",
    "\n",
    "def comparision_plot(set_label, X, v_dtc, v_knn, v_nnc, v_svm, v_rfc, v_etc):\n",
    "    plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "    \n",
    "    X_axis = np.arange(len(X))\n",
    "    width = 0.14\n",
    "    \n",
    "    plt.bar(X_axis-width*2.5, v_dtc, width, label = 'DTC', color='sandybrown')\n",
    "    plt.bar(X_axis-width*1.5, v_knn, width, label = 'KNN', color='lightgreen')\n",
    "    plt.bar(X_axis-width*0.5, v_nnc, width, label = 'NNC', color='lightskyblue')\n",
    "    plt.bar(X_axis+width*0.5, v_svm, width, label = 'SVM', color='lightcoral')\n",
    "    plt.bar(X_axis+width*1.5, v_rfc, width, label = 'RFC', color='gold')\n",
    "    plt.bar(X_axis+width*2.5, v_etc, width, label = 'ETC', color='plum')\n",
    "    \n",
    "    plt.xticks(X_axis, X)\n",
    "    plt.xlabel(\"Metrics\")\n",
    "    plt.ylabel(\"Assert rate\")\n",
    "    plt.title(\"F1 measure performance comparision in {} set \\n (Standardization: {} | Balance: {})\".format(set_label, STANDARDIZATION, BALANCETECNIQUE))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "def reports_comparision(set_label, dtc, knn, nnc, svm, rfc, etc):\n",
    "    X_report = get_x_groups(dtc)\n",
    "    \n",
    "    v_dtc = get_fm_values(dtc)\n",
    "    v_knn = get_fm_values(knn)\n",
    "    v_nnc = get_fm_values(nnc)\n",
    "    v_svm = get_fm_values(svm)\n",
    "    v_rfc = get_fm_values(rfc)\n",
    "    v_etc = get_fm_values(etc)\n",
    "    \n",
    "    comparision_plot(set_label, X_report[:-2], v_dtc[:-2], v_knn[:-2], v_nnc[:-2], v_svm[:-2], v_rfc[:-2], v_etc[:-2])\n",
    "    \n",
    "# test set performance comparision\n",
    "reports_comparision('test', test_report_dtc, test_report_knn, test_report_nnc, test_report_svm, test_report_rfc, test_report_etc)\n",
    "\n",
    "# train set performance comparision\n",
    "reports_comparision('train', train_report_dtc, train_report_knn, train_report_nnc, train_report_svm, train_report_rfc, train_report_etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2285e28f",
   "metadata": {},
   "source": [
    "### Receiver Operating Characteristic (ROC) Curve\n",
    "\n",
    "A _ROC curve_ é uma representação gráfica que ilustra o desempenho de um sistema de classificação binário à medida que o seu _threshold_ varia.\n",
    "\n",
    "Como o nosso problema é um _single label multiclass classification_ com três classes possíveis, calculamos **3 _ROC curves_**:\n",
    "* *Enrolled* vs *Não Enrolled*\n",
    "* *Graduate* vs *Não Graduate*\n",
    "* *Dropout* vs *Não Dropout*\n",
    "\n",
    "NOTA: O algoritmo usado para para o cálculo da ROC curve pode ser alterado. Para tal, basta alterar as variáveis `model` e `model_name` conforme o algoritmo desejado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b94d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import itertools as it\n",
    "\n",
    "def roc(X, y, classes, model, model_name):\n",
    "    # Binarize the output\n",
    "    y = label_binarize(y, classes=classes)\n",
    "    n_classes = y.shape[1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    classifier = OneVsRestClassifier(model)\n",
    "    y_score = None\n",
    "    if model_name == \"SVM\": y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "    else: y_score = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    colors = it.cycle(['blue', 'red', 'green'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                 ''.format(classes[i], roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC for {}'.format(model_name))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot roc curves for different models\n",
    "# Change variables according to what model you want to test\n",
    "# NOTE: Use model_name=\"SVM\" when testing SVC models\n",
    "\n",
    "model = dtc\n",
    "model_name = \"Decision Tree\"\n",
    "\n",
    "roc(data[features], data['class'], classes, model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f146706",
   "metadata": {},
   "source": [
    "### Overfit - Validation Curve\n",
    "\n",
    "É possível detetar o _overfit_ dos modelos se o _score_ obtido em dados de treino for significativamente maior do que o _score_ obtido em dados de teste. Para isso utilizámos uma curva de validação para comparar os dois _scores_, para a qual é necessário fazer variar um determinado parâmetro do modelo para comparar os dois conjuntos de dados ao longo do eixo das abcissas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c51037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "def overfit(model, model_name, values, targets, param_name, param_range):\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        model,\n",
    "        values,\n",
    "        targets,\n",
    "        param_name=param_name,\n",
    "        param_range=param_range,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=4,\n",
    "    )\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.title(\"Validation Curve - {} - {}\".format(model_name, param_name))\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.ylim(0.5, 1.1)\n",
    "    lw = 2\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", lw=lw)\n",
    "    plt.fill_between(\n",
    "        param_range,\n",
    "        train_scores_mean - train_scores_std,\n",
    "        train_scores_mean + train_scores_std,\n",
    "        alpha=0.2,\n",
    "        color=\"darkorange\",\n",
    "        lw=lw,\n",
    "    )\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"navy\", lw=lw)\n",
    "    plt.fill_between(\n",
    "        param_range,\n",
    "        test_scores_mean - test_scores_std,\n",
    "        test_scores_mean + test_scores_std,\n",
    "        alpha=0.2,\n",
    "        color=\"navy\",\n",
    "        lw=lw,\n",
    "    )\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63be195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change arguments of overfit call according to what you want to test\n",
    "\n",
    "param_range = list(range(0, 51, 5))\n",
    "\n",
    "overfit(nnc, \"Neural Network\", values, targets, 'hidden_layer_sizes', param_range)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4dbf65eb2934af93dfe8402dc5043295a9b874b2f4a935919e1627f38520e4d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
