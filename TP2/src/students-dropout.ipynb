{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef4f6572",
   "metadata": {},
   "source": [
    "# Supervised Learning - Classification Problem\n",
    "\n",
    "## Students' dropout and academic success\n",
    "\n",
    "### (Droupout, Enrolled, Graduate)\n",
    "\n",
    "Faculdade: FEUP - Faculdade de Engenharia da Universidade do Porto\n",
    "\n",
    "Curso: L.EIC - Licenciatura em Engenharia Informática e Computação \n",
    "\n",
    "Unidade Curricular: Inteligência Artificial\n",
    "\n",
    "Ano Curricular: 2021/22\n",
    "\n",
    "Grupo: 21_1D\n",
    "\n",
    "Elementos:\n",
    "- Henrique Ribeiro Nunes, up201906852@up.pt\n",
    "- Margarida Assis Ferreira, up201905046@up.pt\n",
    "- Patrícia do Carmo Nunes Oliveira, up201905427@up.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a62f5",
   "metadata": {},
   "source": [
    "### Especificação\n",
    "\n",
    "O foco principal deste problema é analisar a informação conhecida sobre a matrícula do aluno (percurso acadêmico, demografia e fatores socioeconómicos) e o desempenho académico dos alunos no final do primeiro e segundo semestres. Com o objetivo de usar estes dados para construir modelos de classificação para **prever a desistência e o sucesso académico dos alunos**.\n",
    "\n",
    "Este problema é um ***single label multiclass classification problem*** com 37 atributos:\n",
    "- 36 métricas distintas para descrever as informações do aluno.\n",
    "- 1 objetivo com 3 resultados possíveis (*Droupout*, *Enrolled*, *Graduate*).\n",
    "\n",
    "Existe um **forte desbalanceamento** em relação a um dos resultados possíveis.\n",
    "\n",
    "\n",
    "### Tools & Resources\n",
    "\n",
    "// TODO AQUI "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053a6b0",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "A análise dos dados é um passo importante nos problemas de classificação. \n",
    "\n",
    "Nesta secção são analisados os atributos que classificam os dados e o tipo e intervalo de valores de cada um dos atributos, bem como o tamanho do conjunto de dados, a presença de valores nulos ou amostras duplicadas. Igualmente é explorado a distribuição das classes e de valores por atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865da361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca83edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FILE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"data/data_original.csv\")\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc6cec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print head values and summary statistics\n",
    "print(data.describe())\n",
    "print()\n",
    "print(data.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3cba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all 36 features used and 3 possible results\n",
    "features = list(data.columns)\n",
    "features.remove(\"class\")\n",
    "print(\"Number of Features: {}\".format(len(features)))\n",
    "print(\"Features: {}\".format(features))\n",
    "values = list(data[features].values)\n",
    "\n",
    "classes = list(data[\"class\"].unique())\n",
    "classes.sort()\n",
    "print(\"\\nNumber of Results: {}\".format(len(classes)))\n",
    "print(\"Result/Prediction: {}\".format(classes))\n",
    "targets = list(data[\"class\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a89968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check atribute types and values interval\n",
    "for name, dtype in data.dtypes.iteritems():\n",
    "    print(\"{} | {} | [{} , {}] \".format(name.ljust(46), str(dtype).ljust(7), data[name].min(), data[name].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data size\n",
    "print(\"Data Size: {}\".format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2557c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are columns with N/A values\n",
    "print(\"N/A values found: {}\".format(data.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af6dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are duplicated Data\n",
    "bool_series = data.duplicated()\n",
    "print(bool_series)\n",
    "\n",
    "old_size = len(data)\n",
    "\n",
    "# Removing all duplicated data if exists\n",
    "data = data[~bool_series] \n",
    "\n",
    "new_size = len(data)\n",
    "\n",
    "# check if there were actualy duplicated data\n",
    "print()\n",
    "if (new_size == old_size):\n",
    "    print(\"No data was removed: there were no duplicated data\")\n",
    "else:\n",
    "    print(\"Was found and removed {} duplicated data\".format(old_size-new_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d295e9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Resultant data without duplicated entries\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count each class\n",
    "def countEachClass(data):\n",
    "    n_dropouts = data['class'].value_counts().Dropout\n",
    "    n_enrolled = data['class'].value_counts().Enrolled\n",
    "    n_graduate = data['class'].value_counts().Graduate\n",
    "    return n_dropouts, n_enrolled, n_graduate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61232f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleEachClass(data):\n",
    "    class_dropout = data[data['class'] == \"Dropout\"]\n",
    "    class_enrolled = data[data['class'] == \"Enrolled\"]\n",
    "    class_graduate = data[data['class'] == \"Graduate\"]\n",
    "    return class_dropout, class_enrolled, class_graduate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e789768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Distribution\n",
    "# Check data balance\n",
    "n_dropouts, n_enrolled,n_graduate = countEachClass(data)\n",
    "print(\"Number of 'Dropout' occurences: {}\".format(n_dropouts))\n",
    "print(\"Number of 'Enrolled' occurences: {}\".format(n_enrolled))\n",
    "print(\"Number of 'Graduate' occurences: {}\".format(n_graduate))\n",
    "print()\n",
    "\n",
    "# Corresponding plot \n",
    "count_result = pd.DataFrame(data[\"class\"]).value_counts().rename_axis(\"class\").reset_index(name=\"count\")\n",
    "print(count_result)\n",
    "\n",
    "# Bar plot\n",
    "plot_count_res = sb.barplot(data=count_result, x=\"count\", y=\"class\")\n",
    "plt.show()\n",
    "\n",
    "# Pie plot with percentages\n",
    "plt.pie([n_graduate, n_dropouts, n_enrolled], autopct = '%0.00f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd29a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for each feture values and respective count of classses\n",
    "\n",
    "def count_targets_for_each_value(data, feat):\n",
    "    data_aux = data[[feat, \"class\"]]\n",
    "    d = {}\n",
    "    for line in data_aux.values:\n",
    "        if not line[0] in d:\n",
    "            d[line[0]] = {classes[0]: 0, classes[1]: 0, classes[2]: 0}\n",
    "        d[line[0]][line[1]] += 1\n",
    "\n",
    "    for entry in d.keys():\n",
    "        d[entry] = [d[entry][c] for c in classes]\n",
    "    aux = pd.DataFrame(d, index=classes)\n",
    "    return aux.reindex(sorted(aux.columns), axis=1)\n",
    "\n",
    "\n",
    "for i in range(36):\n",
    "    plt.title(features[i])\n",
    "    plt.hist(data[features[i]].values)\n",
    "    plt.show()\n",
    "    print(count_targets_for_each_value(data, features[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e5f0fc",
   "metadata": {},
   "source": [
    "Analisando a distribuição de cada atributo pelas classes possíveis, podemos concluir que existem alguns atributos irrelevantes, na medida que não se distingue à priori nem se obtem qualquer informação sobre qual a classe mais provável para uma nova amostra com base no valor desse atributo, como conseguimos identifificar no caso do atributo 'Curricular units 2nd sem (credited)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c21a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of each attribute \n",
    "def densityPlot(x, hue, fill):\n",
    "    sb.displot(data, x=x, hue=hue, kind=\"kde\", fill=fill)\n",
    "    \n",
    "# all 36 distinct attributes\n",
    "attributes = list(data.columns)\n",
    "attributes.remove(\"class\")\n",
    "    \n",
    "for attribute in attributes:\n",
    "    densityPlot(attribute, 'class', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d2a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "\n",
    "corr = data.corr()\n",
    "\n",
    "sb.set(rc = {'figure.figsize': (15,15) })\n",
    "ax = sb.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sb.diverging_palette(20, 240, n=200),\n",
    "    square=True,\n",
    "    xticklabels=True,\n",
    "    yticklabels=True,\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "plt.show()\n",
    "\n",
    "sb.reset_orig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa5929",
   "metadata": {},
   "source": [
    "**Propriedades do Problema:** (a partir da análise dos dados de entrada)\n",
    "\n",
    "- Nominal and Discrete attributes (including some binary ones)\n",
    "- Dimensionality = 37 attibutos\n",
    "- Size = 4424\n",
    "- Type = Data Matrix\n",
    "- No missing or duplicate Data\n",
    "- No meaningful outliers\n",
    "- Imbalance data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ea0a2",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados\n",
    "\n",
    "Tendo em conta as conclusões obtidas pela a análise dos dados originais mostrada anteriormente, podemos apercebermo-nos que é necessário realizar um pré-processamento dos dados, com o objetivo de resolver o maior problema adjacente a estes: a falta de balanceamento entre as diferentes classes de alvo. \n",
    "\n",
    "Para tal podemos usar entre outras estratégias uma das seguintes:\n",
    "- **oversampling** : «Aumentar o número de amostras/entradas da menor classe até coincidir com o tamanho da maior classe»\n",
    "- **undersampling** : «Diminuir o número de amostras/entradas da maior classe até coincidir com o tamanho da menor classe»\n",
    "\n",
    "Em qualquer uma das abordagens acima, a escolha das amostras escolhidas para serem retidas ou replicadas com pequenas modificações é aleatória."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38bc900",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b3b8af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize(data, to_standardize):\n",
    "    data_to_standardize = data[to_standardize]\n",
    "    scaler = StandardScaler()\n",
    "    stand_values = scaler.fit_transform(data_to_standardize.values)\n",
    "\n",
    "    stand_values_df = pd.DataFrame(\n",
    "        stand_values, \n",
    "        index=data_to_standardize.index, \n",
    "        columns=to_standardize)\n",
    "    data[to_standardize] = stand_values_df[to_standardize]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257397eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_binary_features = [feature for feature in features if len(data[feature].unique()) != 2]\n",
    "data_standard = standardize(data.copy(), non_binary_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa0503",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "\n",
    "Uma das técnicas para lidar com o desbalanceamento de classes em machine lerning é chamado de *undersampling*. Esta técnica de balanceamento consiste em remover algumas observações das classes majoritárias, até que as classes majoritárias e minoritárias sejam equilibradas. A técnica *undersampling* pode ser uma boa escolha quando temos dados desequilibrados, mas uma desvantagem é que removemos informações que podem ser valiosas.\n",
    "\n",
    "Para remover as observações das classes majoritárias, usamos a função `sample(sequence, k)`, uma função do módulo `Random` de Python, que retorna uma lista de comprimento `k` de itens escolhidos aleatoriamente de `sequence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalance Original Data\n",
    "print(\"Classes count:\")\n",
    "print(data['class'].value_counts())\n",
    "\n",
    "data['class'].value_counts().plot(kind='bar', title='count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1232ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersampling(data):\n",
    "    n_dropouts,n_enrolled,n_graduate = countEachClass(data)\n",
    "    class_dropout,class_enrolled,class_graduate = sampleEachClass(data)\n",
    "    \n",
    "    class_dropout_under = class_dropout.sample(n_enrolled, replace=True)\n",
    "    class_graduate_under = class_graduate.sample(n_enrolled, replace=True)\n",
    "    return pd.concat([class_dropout_under, class_graduate_under, class_enrolled], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc02d2c",
   "metadata": {},
   "source": [
    "Agora temos os nossos dados balanceados, como é possível observer no gráfico criado pelo código abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9684b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_under = undersampling(data)\n",
    "\n",
    "# plot the count after under-sampeling\n",
    "print(\"Classes count after under-sampling:\")\n",
    "print(data_under['class'].value_counts())\n",
    "\n",
    "data_under['class'].value_counts().plot(kind='bar', title='count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb5d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "if SAVE_FILE: data_under.to_csv(\"data/data_under.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f401a522",
   "metadata": {},
   "source": [
    "### Oversampling\n",
    "\n",
    "As entradas da classe menor sáo replicadas até totalizarem o número de amostras da classe maior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dropouts,n_enrolled,n_graduate = countEachClass(data)\n",
    "\n",
    "print(\"DROPOUT: {} | ENROLLED: {} | GRADUATE: {}\".format(n_dropouts, n_enrolled, n_graduate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c76c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imbalance Original Data\n",
    "unbalanced_count = data['class'].value_counts()\n",
    "unbalanced_count.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd378cc",
   "metadata": {},
   "source": [
    "#### Random Over-Sampling\n",
    "\n",
    "«Oversampling can be defined as adding more copies to the minority class.»\n",
    "\n",
    "**Desvantagens:** pode causar *overfitting* e pobre generalização do conjunto de dados para teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabeda45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(data):\n",
    "    n_dropouts,n_enrolled,n_graduate = countEachClass(data)\n",
    "    dropout_samples,enrolled_samples,graduate_samples = sampleEachClass(data)\n",
    "\n",
    "    dropout_samples_over = dropout_samples.sample(n_graduate, replace=True)\n",
    "    enrolled_samples_over = enrolled_samples.sample(n_graduate, replace=True)\n",
    "\n",
    "    return pd.concat([graduate_samples, dropout_samples_over, enrolled_samples_over], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7267a07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_over = oversampling(data)\n",
    "print(\"Total dintinct classes: \\n{}\".format(data_over['class'].value_counts()))\n",
    "\n",
    "rnd_oversampling_count = data_over['class'].value_counts()\n",
    "rnd_oversampling_count.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19bff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "if SAVE_FILE: data_over.to_csv(\"data/data_over.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38a7814",
   "metadata": {},
   "source": [
    "É importante referir que nenhuma das soluções acima é uma solução perfeita, pois a aplicação de undersampling pode implicar a perda de infromação, da mesma forma que a aplicação de oversampling (sem qualquer modificação das amostras escolhidas aleatóriamente para serem replicadas) pode levar a um posterior overfitting dos modelos gerados a estes novos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9caea49",
   "metadata": {},
   "source": [
    "### Combine under and over sampling\n",
    "\n",
    "Tendo isto em conta a seguinte tentativa tenta encontrar um meio termos entre as soluções anteriores, fazendo as classes em questão convergir para um valor mediano e não para um máximo nem minímo, tentando combater as consequencias sentidas nos dados ao aplicar isoladamente cada uma das estratégias, obtando por alcaçar um meio termo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c6f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the counts meet at the middle point\n",
    "# in this case the middle point is consider to be the dropout class\n",
    "def combine_sampling(data):\n",
    "    n_dropouts,n_enrolled,n_graduate = countEachClass(data)\n",
    "    dropout_samples,enrolled_samples,graduate_samples = sampleEachClass(data)\n",
    "    graduate_samples_combine = graduate_samples.sample(n_dropouts, replace=True)\n",
    "    enrolled_samples_combine = enrolled_samples.sample(n_dropouts, replace=True)\n",
    "    return pd.concat([graduate_samples_combine, dropout_samples, enrolled_samples_combine], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combine = combine_sampling(data)\n",
    "\n",
    "print(\"Total dintinct classes: \\n{}\".format(data_combine['class'].value_counts()))\n",
    "\n",
    "combine_count = data_combine['class'].value_counts()\n",
    "combine_count.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d367ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "if SAVE_FILE: data_combine.to_csv(\"data/data_combine.csv\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c9dcd",
   "metadata": {},
   "source": [
    "## Learning Algorithms\n",
    "\n",
    "### Identification of the Target Concept\n",
    "\n",
    "A pergunta a que queremos responder é a seguinte: \"Tendo em conta o percurso académico de um aluno e outros fatores externos como é que conseguimos prever se este vai desistir, graduar ou continuar no mesmo ano?\"\n",
    "\n",
    "De forma a avaliar os modelos posterioemente criados podemos escolher nesta secção se os dados a usar ai foram proviamente standarizados e qual o tipo de estratégia para corrigir o balanceamento que é utilizada (inclusive nenhuma). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9407e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data_original.csv')\n",
    "\n",
    "non_binary_features = [feature for feature in features if len(data[feature].unique()) != 2]\n",
    "\n",
    "data = standardize(data, non_binary_features)\n",
    "\n",
    "data = undersampling(data)\n",
    "# data = oversampling(data)\n",
    "# data = combine_sampling(data)\n",
    "\n",
    "values = list(data[list(data.columns[:-1])].values)\n",
    "targets = list(data['class'].values)\n",
    "\n",
    "GRIDSEARCH = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc0c38",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3926cc",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac83c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_data(data, classes, test_size):\n",
    "  feat_train, feat_test, target_train, target_test = train_test_split(data, classes, test_size=test_size, shuffle=True)\n",
    "  return feat_train, feat_test, target_train, target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c0e02",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def cross_validation(model, features, targets, cv):\n",
    "    scores = cross_val_score(model, features, targets, cv=cv)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2d0ac",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed661554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "def confusion_matrix(target_test, target_predictions):    \n",
    "    return metrics.confusion_matrix(target_test, target_predictions)\n",
    "\n",
    "def display_confusion_matrix(cm):\n",
    "    metrics.ConfusionMatrixDisplay(cm, display_labels=classes).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677c27f",
   "metadata": {},
   "source": [
    "#### Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4c552f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def precision(cm, i):\n",
    "    return cm[i][i]/sum(cm[i])\n",
    "\n",
    "def recall(cm, i):\n",
    "    cmt = np.copy(cm).transpose()\n",
    "    return cmt[i][i]/sum(cmt[i])\n",
    "\n",
    "def f_measure(cm, i):\n",
    "    p = precision(cm, i)*100\n",
    "    r = recall(cm, i)*100\n",
    "    return 2 * (p * r) / (p + r)\n",
    "\n",
    "def validate(model, features, targets):\n",
    "    test_size = 0.2\n",
    "    cross_validation_split = 5\n",
    "    feat_train, feat_test, target_train, target_test = split_data(features, targets, test_size)\n",
    "    \n",
    "    model.fit(feat_train, target_train)\n",
    "    predictions = model.predict(feat_test)\n",
    "    \n",
    "    acc = metrics.accuracy_score(target_test, predictions)\n",
    "    print(\"Accuracy: {:.2f}\\n\".format(acc*100))\n",
    "    \n",
    "    cm = confusion_matrix(target_test, predictions)\n",
    "    print(\"Precision:\")\n",
    "    for i in range(3): print(\"\\t{:.2f}% - {}\".format(precision(cm, i)*100, classes[i]))\n",
    "    print(\"Recall:\")\n",
    "    for i in range(3): print(\"\\t{:.2f}% - {}\".format(recall(cm, i)*100, classes[i]))\n",
    "    print(\"F1-measure:\")\n",
    "    for i in range(3): print(\"\\t{:.2f}% - {}\".format(f_measure(cm, i), classes[i]))\n",
    "    \n",
    "    display_confusion_matrix(cm)\n",
    "    \n",
    "    scores = cross_validation(model, features, targets, cross_validation_split)\n",
    "    print(\"Cross validation {}-fold: {}\".format(cross_validation_split, [round(x, 3) for x in scores]))\n",
    "    print(\"\\t{:.2f} accuracy with a standard deviation of {:.2f}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02422a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_search(model, grid_params, features, targets):\n",
    "    test_size = 0.2\n",
    "    cross_validation_split = 5\n",
    "    feat_train, feat_test, target_train, target_test = split_data(features, targets, test_size)\n",
    "    \n",
    "    gs = GridSearchCV(\n",
    "        model,\n",
    "        grid_params,\n",
    "        verbose = 1,\n",
    "        n_jobs = 1,\n",
    "        cv = cross_validation_split,\n",
    "    )\n",
    "    \n",
    "    gs_results = gs.fit(feat_train, target_train)\n",
    "    \n",
    "    print(\"best score: \" + str(gs_results.best_score_))\n",
    "    print(\"best estimator: \" + str(gs_results.best_estimator_))\n",
    "    print(\"best parameters: \" + str(gs_results.best_params_))\n",
    "    \n",
    "    return gs_results.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a876e5",
   "metadata": {},
   "source": [
    "### Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05548a8",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5b17ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "grid_params_dtc = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'], \n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [5, 6, 7, 8, 9, 10, 15, 20, 50],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_leaf_nodes': [None, 5, 10, 20],\n",
    "}\n",
    "\n",
    "def_params_dtc = {'criterion': 'entropy', 'max_depth': 7, 'max_features': None, 'max_leaf_nodes': None, 'splitter': 'random'}\n",
    "best_params_dtc = grid_search(DecisionTreeClassifier(), grid_params_dtc, values, targets) if GRIDSEARCH else def_params_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create the classifier\n",
    "dtc = DecisionTreeClassifier(\n",
    "  criterion= best_params_dtc['criterion'], \n",
    "  splitter= best_params_dtc['splitter'], \n",
    "  max_depth= best_params_dtc['max_depth'], \n",
    "  max_features = best_params_dtc['max_features'], \n",
    "  max_leaf_nodes= best_params_dtc['max_leaf_nodes']) \n",
    "validate(dtc, values, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot tree\n",
    "from sklearn.tree import plot_tree\n",
    "plot_tree(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73281f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PDF with the tree\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "'''\n",
    "dot_data = export_graphviz(dtc, out_file=None, feature_names=features, class_names=targets ) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"decision_tree\") \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bbf312",
   "metadata": {},
   "source": [
    "#### K-nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5831201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "grid_params_knn = {\n",
    "    'n_neighbors': [3,5,11,19], \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "}\n",
    "\n",
    "def_params_knn = {'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
    "best_params_knn = grid_search(KNeighborsClassifier(), grid_params_knn, values, targets) if GRIDSEARCH else def_params_knn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84996ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knc = KNeighborsClassifier(best_params_knn['n_neighbors'],\n",
    "                           weights = best_params_knn['weights'],\n",
    "                           metric = best_params_knn['metric'])\n",
    "validate(knc, values, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "'''\n",
    "_, ax = plt.subplots()\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "    clf,\n",
    "    X=np.array([line[:2] for line in data_train]),\n",
    "    ax=ax,\n",
    "    response_method=\"predict\",\n",
    "    plot_method=\"pcolormesh\",\n",
    "    shading=\"auto\",\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "        x=data[labels[0]],\n",
    "        y=data[labels[1]],\n",
    "        alpha=1.0,\n",
    "        edgecolor=\"black\",\n",
    "    )\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44df5cb",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6055deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "grid_params_mlp = {\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'], \n",
    "    'alpha': [1e-5, 1e-1],\n",
    "    'hidden_layer_sizes': [(5, 2)],\n",
    "    'max_iter':[5000, 2500],\n",
    "    'random_state':[None, 1],\n",
    "}\n",
    "\n",
    "def_params_mlp = {'alpha': 0.1, 'hidden_layer_sizes': (5, 2), 'max_iter': 5000, 'random_state': 1, 'solver': 'sgd'}\n",
    "best_params_mlp = grid_search(MLPClassifier(), grid_params_mlp, values, targets) if GRIDSEARCH else def_params_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b5d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nnc = MLPClassifier(\n",
    "    solver = best_params_mlp['solver'], \n",
    "    alpha = best_params_mlp['alpha'],\n",
    "    hidden_layer_sizes = best_params_mlp['hidden_layer_sizes'],\n",
    "    max_iter = best_params_mlp['max_iter'],\n",
    "    random_state = best_params_mlp['random_state'])\n",
    "\n",
    "validate(nnc, values, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c028818",
   "metadata": {},
   "source": [
    "### Evaluation of the learning process\n",
    "\n",
    "No que diz respeito à avaliação do processo de aprendizagem foi implementada a função `validate` (apresentada na secção de *Validation*) que é responsável por dividir os dados em dados de treino e de teste, bem como avaliar os resultados obtidos em cada um dos modelos criados usando as métricas apropriadas: ***accuracy***, ***precision***, ***recall***, ***F-measure*** e ***confusion matrix***, tendo sempre em consideração as características do problema: o problema trata-se um um problema de classificação ***multiclass single label*** com 3 diferentes classes objetivo (3 *targets*). Esta avaliação centra-se principalmente no conjunto de dados de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f4c3dc",
   "metadata": {},
   "source": [
    "### Results Comparision\n",
    "\n",
    "O resultados apresentados foram obtidos apartir da comparaação da avaliação de performance dos diferentes modelos considerando as seguintes combinações nas variações da data de entrada:\n",
    "\n",
    "- aplicação de **standarização** aos dados: *yes/no*\n",
    "- estratégia para **tratamento do desbalanceamento** dos dados: *none/under/over/combined*\n",
    "- **gridsearch** para escolha dos melhores parametros a usar para cada algoritmo: *yes/no*\n",
    "\n",
    "NOTA: Estes parametros podem ser ajustados e configurados no início da secção ***Learning Algorithms, «Identification of the Target Concept»***.\n",
    "\n",
    "Neste sentido foram comparados os resultados obtidos para cada uma das combinações possíveis para os 3 algoritmos apresentados anteriormente : ***Decision Tree Classifier***, ***K-Nearest Neighbor***, ***Neural Networks***, resultando nos seguintes gráficos e tabelas apresentados em seguida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3d643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4dbf65eb2934af93dfe8402dc5043295a9b874b2f4a935919e1627f38520e4d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
